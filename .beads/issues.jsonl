{"id":"dictate.sh-09p","title":"Create __init__.py files for package and subpackages","description":"Create:\n- src/dictate/__init__.py: __version__ = '0.1.0' only. No eager re-exports (avoid triggering MLX import).\n- src/dictate/audio/__init__.py: re-export RingBuffer, VoiceActivityDetector, VadConfig\n- src/dictate/model/__init__.py: re-export Qwen3ASRModel, load_qwen3_asr\nKeep audio/ and model/ __init__.py imports lazy-safe (these modules import MLX).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:55.807799+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:51.215107+05:30","closed_at":"2026-02-03T21:57:51.215107+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-6ws","type":"blocks","created_at":"2026-02-03T21:41:11.07059+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-eyb","type":"blocks","created_at":"2026-02-03T21:41:11.136323+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:11.201193+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-1jx","title":"Add litellm dependency","description":"Add litellm as a project dependency for LLM-based transcript rewriting.\n\nCHANGE pyproject.toml:\n- Add \"litellm\u003e=1.40\" to the dependencies list (after the existing deps like rich, webrtcvad-wheels, etc.)\n\nlitellm provides a unified completion() API supporting Ollama, OpenAI, Claude, and 100+ providers. Used by the notes pipeline to rewrite transcripts via external LLMs.\n\nFILES: pyproject.toml\nVERIFY: uv sync \u0026\u0026 .venv/bin/python -c \"import litellm; print(litellm.__version__)\"","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:14.829359+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T08:46:44.728034+05:30","closed_at":"2026-02-04T08:46:44.728034+05:30","close_reason":"Closed"}
{"id":"dictate.sh-1l1","title":"Create src/dictate/notes.py","description":"Create the notes pipeline orchestrator at src/dictate/notes.py. This module wires up STT + LLM rewriting + file output.\n\nCREATE src/dictate/notes.py with:\n\n1. NotesConfig(frozen=True, slots=True) dataclass:\n   - rewrite: RewriteConfig\n   - output_path: Path\n\n2. resolve_notes_path(notes_file: str | None) -\u003e Path:\n   - Priority: --notes-file flag (absolute or relative to cwd) \u003e DICTATE_NOTES_DIR env var \u003e ~/.local/share/dictate/notes/\n   - Creates directory with mkdir(parents=True, exist_ok=True)\n   - Auto-names file as YYYY-MM-DD_HHMM.md (datetime.now())\n   - Returns resolved Path\n\n3. load_system_prompt(prompt: str | None, file: str | None) -\u003e str | None:\n   - Returns prompt if given, else reads file contents, else None\n\n4. write_session_header(path: Path) -\u003e None:\n   - Writes \"# Notes — YYYY-MM-DD HH:MM\\n\\n\" to new file\n\n5. append_turn(path: Path, result: RewriteResult) -\u003e None:\n   - Opens file in append mode\n   - Writes result.rewritten + \"\\n\\n\" (or result.original on error with LOGGER.warning)\n   - Flushes immediately for crash resilience\n\n6. run_notes_pipeline(model_path, language, context, transcribe_interval, vad_frame_ms, vad_mode, vad_silence_ms, min_words, device, notes_config) -\u003e None:\n   - Creates RealtimeTranscriber with no_ui=True, analyze=False, context=context\n   - Passes async on_turn_complete closure that:\n     a. Increments turn_count\n     b. Logs turn to stderr: LOGGER.info(\"Turn %d: %s\", ...)\n     c. Calls rewrite_transcript via asyncio.to_thread()\n     d. Calls append_turn()\n     e. Logs rewrite success\n   - Logs output file path at startup\n   - Calls await transcriber.run()\n\nFILES: src/dictate/notes.py\nDEPENDS ON: dictate.sh-ybt (rewrite.py), dictate.sh-fr1 (on_turn_complete callback)\nVERIFY: .venv/bin/python -c \"from dictate.notes import NotesConfig, resolve_notes_path, run_notes_pipeline\"","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:52.156197+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:40:52.156197+05:30","dependencies":[{"issue_id":"dictate.sh-1l1","depends_on_id":"dictate.sh-ybt","type":"blocks","created_at":"2026-02-03T23:41:23.03803+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-1l1","depends_on_id":"dictate.sh-fr1","type":"blocks","created_at":"2026-02-03T23:41:23.131514+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-2ls","title":"Verify uv sync and CLI entry points work","description":"Run verification steps:\n1. uv sync — ensure package installs in dev mode without errors\n2. uv run dictate --help — verify [project.scripts] entry point works\n3. uv run stt.py --help — verify thin shim resolves imports correctly\n4. uv run dictate --list-devices — verify sounddevice integration works\nFix any import errors, missing modules, or dependency issues discovered.\nThis is the integration test gate — all prior tasks must be complete.","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:38:07.25174+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:04:11.927017+05:30","closed_at":"2026-02-03T22:04:11.927017+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-2ls","depends_on_id":"dictate.sh-7jf","type":"blocks","created_at":"2026-02-03T21:41:11.333855+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-2ls","depends_on_id":"dictate.sh-09p","type":"blocks","created_at":"2026-02-03T21:41:11.400067+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-36o","title":"Update CLAUDE.md and ARCHITECTURE.md for notes feature","description":"Update project documentation to reflect the notes pipeline and context biasing features.\n\nCHANGE CLAUDE.md:\n- Update File Layout to include rewrite.py and notes.py\n- Add litellm\u003e=1.40 to dependencies list\n- Update Run commands to mention \"uv run dictate notes\"\n- Update project description (no longer \"being refactored\" — refactor is complete)\n\nCHANGE ARCHITECTURE.md:\n- Add notes pipeline section describing the two-layer architecture:\n  1. ASR context biasing (domain vocab in Qwen3-ASR system prompt)\n  2. LLM rewriting (litellm -\u003e Ollama/OpenAI for markdown formatting)\n- Document the on_turn_complete callback pattern\n- Document the subcommand CLI structure\n\nFILES: CLAUDE.md, ARCHITECTURE.md\nDEPENDS ON: dictate.sh-ylf (CLI restructure complete — all code done)","status":"open","priority":3,"issue_type":"chore","owner":"jaju@msync.org","created_at":"2026-02-03T23:41:12.590329+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:41:12.590329+05:30","dependencies":[{"issue_id":"dictate.sh-36o","depends_on_id":"dictate.sh-ylf","type":"blocks","created_at":"2026-02-03T23:41:23.4175+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-590","title":"Create transcribe.py with streaming ASR generator","description":"Create src/dictate/transcribe.py. Extract from stt.py lines 885-970:\n- transcribe() generator function — streams tokens for low-latency output\n- Use collections.abc.Generator not typing.Generator\n- Deferred import of mlx_lm.generate.generate_step inside function body\n- Uses get_feat_extract_output_lengths from model._utils\n- Note: duplicated audio-feature replacement logic exists in both Qwen3ASRModel.__call__ and transcribe(). Keep the transcribe() version (it's the one used at inference time).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:20.924831+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:51.14897+05:30","closed_at":"2026-02-03T21:57:51.14897+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-590","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:10.011174+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-590","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:41:10.080843+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-5iv","title":"Create pipeline.py with slimmed RealtimeTranscriber","description":"Create src/dictate/pipeline.py. Refactor RealtimeTranscriber from stt.py lines 986-1568 into orchestration-only class:\n- __init__: create RingBuffer, VoiceActivityDetector, UiState; store config\n- _audio_callback: thin sounddevice callback (unchanged logic)\n- _processor: async loop coordinating audio capture, VAD, periodic ASR\n- _display: async loop for UI updates and stdout output\n- _handle_turn_complete: orchestrate final transcription + optional analysis\n- run: lifecycle (model loading, warmup, stream, signal handling)\nModule-level function: is_meaningful(text: str) -\u003e bool\nDelegates to: RingBuffer, VoiceActivityDetector, transcribe(), analyze_intent(), ui.render_layout()\nAll self.ui_* attributes replaced by single UiState instance.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:46.455529+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:59:17.436792+05:30","closed_at":"2026-02-03T21:59:17.436792+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-qq8","type":"blocks","created_at":"2026-02-03T21:41:10.34491+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.409543+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:10.476279+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-590","type":"blocks","created_at":"2026-02-03T21:41:10.544215+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-6ws","type":"blocks","created_at":"2026-02-03T21:41:10.610437+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-eyb","type":"blocks","created_at":"2026-02-03T21:41:10.675288+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-cfe","type":"blocks","created_at":"2026-02-03T21:41:10.741883+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-mit","type":"blocks","created_at":"2026-02-03T21:41:10.807717+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-6ws","title":"Create audio/ring_buffer.py","description":"Create src/dictate/audio/ring_buffer.py. Extract ring buffer logic from RealtimeTranscriber (stt.py lines 1029-1034, 1175-1215):\n- RingBuffer class with __slots__\n- Factory: classmethod create(max_seconds, sample_rate) -\u003e Self\n- Methods: append(frame), get_recent(seconds) -\u003e np.ndarray, reset()\n- Properties: filled_seconds, total_samples_written, sample_rate\n- Track total_samples_written and last_transcribed_sample internally\n- Only depends on numpy","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:05.918827+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.831691+05:30","closed_at":"2026-02-03T21:51:52.831691+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-6ws","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.165941+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-7jf","title":"Replace root stt.py with thin shim","description":"Replace the root stt.py with a thin shim that imports from the package:\n- Keep PEP 723 script metadata block with requires-python\u003e=3.12\n- dependencies list: just 'dictate-stt'\n- [tool.uv.sources] dictate-stt = { path = '.' }\n- Body: from dictate.cli import main; raise SystemExit(main())\n- Keep the original docstring as a one-liner\nThe original full stt.py in docs/ stays unchanged for now (it serves the landing page download).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:38:01.924491+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:02:04.940174+05:30","closed_at":"2026-02-03T22:02:04.940174+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-7jf","depends_on_id":"dictate.sh-rie","type":"blocks","created_at":"2026-02-03T21:41:11.267533+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-a05","title":"Create config.py with frozen dataclasses and factory","description":"Create src/dictate/config.py. Extract from stt.py lines 180-237:\n- AudioEncoderConfig: @dataclass(frozen=True, slots=True) — all fields from original\n- TextConfig: @dataclass(frozen=True, slots=True) — all fields from original\n- ModelConfig: @dataclass(frozen=True, slots=True) — audio_config, text_config, audio_token_id, support_languages as tuple[str, ...] not list\n- Remove __post_init__ mutation. Add make_model_config(raw: dict[str, Any]) -\u003e ModelConfig factory function that resolves nested dicts into frozen sub-configs before constructing the frozen ModelConfig.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:34:35.071111+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.76498+05:30","closed_at":"2026-02-03T21:51:52.76498+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-a05","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.099916+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-bia","title":"Add ASR context biasing to transcribe.py","description":"Add optional context: str | None parameter to transcribe() in src/dictate/transcribe.py. When provided, inject into Qwen3-ASR system prompt for domain vocabulary biasing.\n\nWHAT: Qwen3-ASR has native context biasing trained during SFT. The system prompt in the chat template (currently empty at transcribe.py:54-55) accepts domain vocabulary text that biases the decoder toward specific terms.\n\nCHANGE transcribe.py:\n- Add context: str | None = None parameter to transcribe() function signature (line 17-24)\n- Change prompt construction (line 54-55) from:\n    f\"\u003c|im_start|\u003esystem\\n\u003c|im_end|\u003e\\n\"\n  to:\n    f\"\u003c|im_start|\u003esystem\\n{context or chr(39)+chr(39)}\u003c|im_end|\u003e\\n\"\n\nCHANGE pipeline.py:\n- Add context: str | None = None parameter to RealtimeTranscriber.__init__ (line 54-67)\n- Store as self.context\n- Pass self.context to transcribe() call in _run_transcribe method (around line 160)\n\nCHANGE cli.py:\n- Add mutually exclusive group with --context (inline string) and --context-file (path to file)\n- In main(), read context-file if provided, pass context string to RealtimeTranscriber\n\nFILES: src/dictate/transcribe.py, src/dictate/pipeline.py, src/dictate/cli.py\nVERIFY: .venv/bin/python -c \"from dictate.transcribe import transcribe; import inspect; assert \\\"context\\\" in inspect.signature(transcribe).parameters\"","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:03.264342+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:40:03.264342+05:30"}
{"id":"dictate.sh-c2k","title":"Create model/_utils.py with tensor math helpers","description":"Create src/dictate/model/_utils.py. Extract from stt.py lines 245-267:\n- create_additive_causal_mask(n, offset) -\u003e mx.array\n- floor_div(a, b) -\u003e mx.array  (renamed from _floor_div)\n- get_feat_extract_output_lengths(input_lengths) -\u003e mx.array (renamed from _get_feat_extract_output_lengths)\nUse type statement for aliases: type MaskArray = mx.array\nAll pure functions, no state. Depends on mlx.core.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:25.660127+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.965497+05:30","closed_at":"2026-02-03T21:51:52.965497+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-c2k","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:30.391361+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-cfe","title":"Create analysis.py with IntentResult and analyze_intent","description":"Create src/dictate/analysis.py. Extract from stt.py lines 978-983, 1268-1298:\n- INTENT_EXPLAIN_PROMPT: Final (the prompt template)\n- IntentResult: @dataclass(frozen=True, slots=True) with intent, entities, action fields — replaces dict[str, str]\n- analyze_intent(text, llm, llm_tokenizer) -\u003e IntentResult — pure function\n- Deferred import of mlx_lm.generate.generate inside function body\n- Uses suppress_output from dictate.env\n- Strips \u003cthink\u003e...\u003c/think\u003e tags from LLM output","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:31.349746+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.247231+05:30","closed_at":"2026-02-03T21:54:01.247231+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-cfe","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.148596+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-cfe","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:41:10.214354+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-cys","title":"Create model/decoder.py with text decoder nn.Modules","description":"Create src/dictate/model/decoder.py. Extract from stt.py lines 550-675:\n- TextAttention(nn.Module) — GQA with RoPE, QK-norm\n- TextMLP(nn.Module) — SwiGLU\n- TextDecoderLayer(nn.Module) — pre-norm transformer block\n- TextModel(nn.Module) — embedding + N layers + final RMSNorm\nUse @override on __call__ methods. Import config types from dictate.config, create_additive_causal_mask from dictate.model._utils.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:45.62525+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.179713+05:30","closed_at":"2026-02-03T21:54:01.179713+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-cys","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.591243+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-cys","depends_on_id":"dictate.sh-c2k","type":"blocks","created_at":"2026-02-03T21:39:30.657124+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ehy","title":"Add notes-related constants","description":"Add Final-annotated constants to src/dictate/constants.py for the notes pipeline.\n\nADD to constants.py:\n- DEFAULT_NOTES_DIR: Final = \"~/.local/share/dictate/notes\"\n- DEFAULT_NOTES_DIR_ENV: Final = \"DICTATE_NOTES_DIR\"\n- DEFAULT_REWRITE_MAX_TOKENS: Final = 2048\n- DEFAULT_REWRITE_SYSTEM_PROMPT: Final = \"You are a note-taking assistant. Rewrite the following spoken transcript into clean, structured markdown notes. Preserve all information but improve clarity, fix grammar, and organize with headings or bullet points as appropriate. Output only the markdown, no preamble.\"\n\nFILES: src/dictate/constants.py\nVERIFY: .venv/bin/python -c \"from dictate.constants import DEFAULT_NOTES_DIR, DEFAULT_NOTES_DIR_ENV, DEFAULT_REWRITE_MAX_TOKENS, DEFAULT_REWRITE_SYSTEM_PROMPT; print(DEFAULT_NOTES_DIR)\"","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:09.7547+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T08:46:44.664208+05:30","closed_at":"2026-02-04T08:46:44.664208+05:30","close_reason":"Closed"}
{"id":"dictate.sh-eyb","title":"Create audio/vad.py with VadConfig and VoiceActivityDetector","description":"Create src/dictate/audio/vad.py. Extract VAD logic from RealtimeTranscriber (stt.py lines 1041-1053, 1219-1248):\n- VadConfig: @dataclass(frozen=True, slots=True) with frame_ms, mode, silence_ms, sample_rate\n- VoiceActivityDetector class with __slots__\n- __init__(config: VadConfig) — validates frame_ms in (10,20,30) and mode in 0-3\n- process(frame: np.ndarray) -\u003e bool — returns True on turn complete\n- reset() — clear state for new turn\n- Properties: state ('speech'|'silence'), speech_detected\n- Depends on numpy, webrtcvad-wheels, math","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:17.656072+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.897683+05:30","closed_at":"2026-02-03T21:51:52.897683+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-eyb","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.233994+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-fhb","title":"Create model/__init__.py with re-exports","description":"Create src/dictate/model/__init__.py. Re-export:\n- Qwen3ASRModel from dictate.model.asr\n- load_qwen3_asr from dictate.model.loader\nThese are the public API of the model subpackage.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:12.474512+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:07.759132+05:30","closed_at":"2026-02-03T21:57:07.759132+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-fhb","depends_on_id":"dictate.sh-sc4","type":"blocks","created_at":"2026-02-03T21:39:31.124+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-fhb","depends_on_id":"dictate.sh-hm5","type":"blocks","created_at":"2026-02-03T21:39:31.190768+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-fr1","title":"Add on_turn_complete callback to RealtimeTranscriber","description":"Add an optional async callback to RealtimeTranscriber that fires when a turn is finalized. This is the integration point for the notes pipeline.\n\nCHANGE src/dictate/pipeline.py:\n\n1. Add import at top: from collections.abc import Callable\n\n2. Add parameter to __init__ (line 54-67):\n   on_turn_complete: Callable[[str], Any] | None = None\n   Store as self.on_turn_complete\n\n3. In _handle_turn_complete() (around line 200-204), AFTER:\n   self.pending_analysis = (final_transcript, analysis_result)\n   and BEFORE the buffer reset (line 205), add:\n   if self.on_turn_complete is not None:\n       await self.on_turn_complete(final_transcript)\n\nDESIGN NOTES:\n- The callback is awaited sequentially — turns are processed in order (no out-of-order file writes)\n- The callback does NOT hold the GPU lock — litellm calls go to external LLM, not local MLX GPU\n- Backward-compatible: existing callers pass nothing, behavior unchanged\n- The callback runs AFTER analysis (if enabled) but BEFORE buffer reset\n\nFILES: src/dictate/pipeline.py\nDEPENDS ON: dictate.sh-bia (context biasing, since both touch pipeline.py — avoids merge conflicts)\nVERIFY: .venv/bin/python -c \"from dictate.pipeline import RealtimeTranscriber; import inspect; sig = inspect.signature(RealtimeTranscriber.__init__); assert \\\"on_turn_complete\\\" in sig.parameters\"","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:36.872758+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:40:36.872758+05:30","dependencies":[{"issue_id":"dictate.sh-fr1","depends_on_id":"dictate.sh-bia","type":"blocks","created_at":"2026-02-03T23:41:22.945576+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-hm5","title":"Create model/loader.py with load_qwen3_asr function","description":"Create src/dictate/model/loader.py. Extract from stt.py lines 789-877:\n- load_qwen3_asr(model_path: str) -\u003e tuple[Qwen3ASRModel, TokenizerLike, FeatureExtractorLike]\n- Replace glob.glob with Path.glob\n- Use make_model_config() factory from dictate.config\n- Keep trust_remote_code=True (required by Qwen3 tokenizer)\n- Keep strict=False weight loading (model weight format varies)\nDepends on mlx, json, pathlib, huggingface_hub, transformers, config, asr, protocols.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:07.44807+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:48.581952+05:30","closed_at":"2026-02-03T21:56:48.581952+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.923634+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-sc4","type":"blocks","created_at":"2026-02-03T21:39:30.99023+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:39:31.058119+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-htw","title":"Create env.py with environment setup and logging","description":"Create src/dictate/env.py. Extract from stt.py:\n- Lines 71-84: warning filters + os.environ setup → setup_environment() function\n- Lines 128-142: _suppress_output() context manager → suppress_output() (public name)\n- Line 125: LOGGER = logging.getLogger('speech')\nOnly stdlib imports (contextlib, io, os, logging, warnings). setup_environment() must be called before any MLX imports.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:33:59.074448+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.629838+05:30","closed_at":"2026-02-03T21:51:52.629838+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-htw","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:15.969408+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ma1","title":"Create pyproject.toml with uv project config","description":"Create pyproject.toml at project root with:\n- name='dictate-stt', version='0.1.0', requires-python='\u003e=3.12'\n- Updated dependencies: mlx\u003e=0.30.0, mlx-lm\u003e=0.30.0, numpy\u003e=2.0, sounddevice\u003e=0.5, transformers\u003e=4.47, huggingface-hub\u003e=0.27, webrtcvad-wheels\u003e=2.0.14, rich\u003e=14.0\n- Drop setuptools (unused transitive dep)\n- [project.scripts] dictate = 'dictate.cli:main'\n- [build-system] hatchling\n- [tool.hatch.build.targets.wheel] packages = ['src/dictate']\n- Create src/dictate/ directory structure with empty __init__.py files for: dictate/, dictate/model/, dictate/audio/","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:32:38.93503+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:47:19.849875+05:30","closed_at":"2026-02-03T21:47:19.849875+05:30","close_reason":"Closed"}
{"id":"dictate.sh-mit","title":"Create ui.py with UiState and pure render functions","description":"Create src/dictate/ui.py. Extract rendering from RealtimeTranscriber (stt.py lines 1086-1168):\n- UiState: @dataclass(slots=True) — snapshot of all pipeline state needed for rendering\n  Fields: status, partial_transcript, history (list of (str, IntentResult|None)), max_history, vad_state, buffer_seconds, queue_size, asr_ms, analysis_ms, language, vad_mode, vad_frame_ms, model_path, llm_model_name, analyze_enabled, turn_complete\n- short_model_name(name: str | None) -\u003e str — extract last path segment\n- render_status_panel(state: UiState) -\u003e Panel\n- render_transcript_panel(state: UiState) -\u003e Panel\n- render_stats_panel(state: UiState) -\u003e Panel\n- render_layout(state: UiState) -\u003e Layout\nAll render functions are pure: take UiState in, return Rich renderables out. No side effects.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:39.059004+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:13.006272+05:30","closed_at":"2026-02-03T21:56:13.006272+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-mit","depends_on_id":"dictate.sh-cfe","type":"blocks","created_at":"2026-02-03T21:41:10.27998+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-oej","title":"Create protocols.py with TokenizerLike and FeatureExtractorLike","description":"Create src/dictate/protocols.py. Extract Protocol classes from stt.py lines 150-172. Modernize:\n- Use list[int], dict[str, Any] not List/Dict\n- Use collections.abc.Sequence not typing.Sequence\n- Keep as Protocol classes (structural typing, no implementation)","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:34:14.499002+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.696398+05:30","closed_at":"2026-02-03T21:51:52.696398+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-oej","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.034135+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-qq8","title":"Create constants.py with Final-annotated defaults","description":"Create src/dictate/constants.py. Extract all DEFAULT_* constants from stt.py lines 109-119. Use typing.Final annotations. Use underscore separators in numbers (16_000). No imports beyond typing.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:33:49.788192+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.561949+05:30","closed_at":"2026-02-03T21:51:52.561949+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-qq8","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:15.901435+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-rie","title":"Create cli.py with argparse and main entry point","description":"Create src/dictate/cli.py. Extract from stt.py lines 1576-1688:\n- build_arg_parser() -\u003e argparse.ArgumentParser\n- list_audio_devices() -\u003e None (Rich table of input devices)\n- main() -\u003e int\nmain() must call setup_environment() BEFORE importing pipeline (which transitively imports MLX).\nUse deferred import: import pipeline inside main() body after setup_environment().\nConfigure logging with RichHandler to stderr.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:51.041499+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:01:44.297962+05:30","closed_at":"2026-02-03T22:01:44.297962+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-qq8","type":"blocks","created_at":"2026-02-03T21:41:10.873246+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.939345+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-5iv","type":"blocks","created_at":"2026-02-03T21:41:11.004923+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-sc4","title":"Create model/asr.py with Qwen3ASRModel composite","description":"Create src/dictate/model/asr.py. Extract from stt.py lines 678-781:\n- Qwen3ASRModel(nn.Module) — composes AudioEncoder + TextModel\n- get_audio_features(), __call__() with @override, make_cache(), sanitize() @staticmethod\n- type Weights = dict[str, mx.array]\n- Properties: layers, sample_rate\nImport AudioEncoder from encoder.py, TextModel from decoder.py, ModelConfig from config.py.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:36:42.445267+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:12.939297+05:30","closed_at":"2026-02-03T21:56:12.939297+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.723225+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-wzi","type":"blocks","created_at":"2026-02-03T21:39:30.789213+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-cys","type":"blocks","created_at":"2026-02-03T21:39:30.855584+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-wzi","title":"Create model/encoder.py with audio encoder nn.Modules","description":"Create src/dictate/model/encoder.py. Extract from stt.py lines 270-547:\n- SinusoidalPositionEmbedding(nn.Module)\n- AudioAttention(nn.Module)\n- AudioEncoderLayer(nn.Module)\n- AudioEncoder(nn.Module)\nExtract stateless helpers as module-level functions (not methods):\n- compute_chunk_layout(feature_lens, chunk_size) -\u003e tuple[np.ndarray, np.ndarray]\n- slice_feature_chunks(...) -\u003e list[mx.array]\n- pad_chunks(...) -\u003e tuple[mx.array, int]\n- build_cu_seqlens(...) -\u003e list[int]\nUse @override on __call__ methods. Import config types from dictate.config, utils from dictate.model._utils.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:33.67463+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.111955+05:30","closed_at":"2026-02-03T21:54:01.111955+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-wzi","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.458803+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-wzi","depends_on_id":"dictate.sh-c2k","type":"blocks","created_at":"2026-02-03T21:39:30.524758+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ybt","title":"Create src/dictate/rewrite.py","description":"Create the LLM rewriting module at src/dictate/rewrite.py. Analogous to analysis.py but for transcript-to-markdown rewriting via litellm.\n\nCREATE src/dictate/rewrite.py with:\n\n1. RewriteConfig(frozen=True, slots=True) dataclass:\n   - model: str (e.g. \"ollama/llama3.2\", \"openai/gpt-4o-mini\")\n   - system_prompt: str = DEFAULT_REWRITE_SYSTEM_PROMPT (from constants)\n   - max_tokens: int = DEFAULT_REWRITE_MAX_TOKENS (from constants)\n\n2. RewriteResult(frozen=True, slots=True) dataclass:\n   - original: str (raw transcript)\n   - rewritten: str (LLM output)\n   - model: str (which model was used)\n   - error: str = \"\" (non-empty on failure)\n\n3. rewrite_transcript(text: str, config: RewriteConfig) -\u003e RewriteResult:\n   - Blocking function (designed for asyncio.to_thread)\n   - Deferred import: from litellm import completion\n   - Sends system_prompt as system role, text as user role\n   - Captures ALL exceptions in result.error (does not raise) — pipeline must keep going\n   - Returns RewriteResult\n\nPATTERNS TO FOLLOW (from analysis.py):\n- Frozen dataclass results\n- Deferred imports inside function body\n- Pure function, no state, no side effects beyond LLM call\n- Use Python 3.12 types: str | None, not Optional[str]\n\nFILES: src/dictate/rewrite.py\nDEPENDS ON: dictate.sh-ehy (constants), dictate.sh-1jx (litellm dep)\nVERIFY: .venv/bin/python -c \"from dictate.rewrite import RewriteConfig, RewriteResult, rewrite_transcript\"","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:26.405534+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:40:26.405534+05:30","dependencies":[{"issue_id":"dictate.sh-ybt","depends_on_id":"dictate.sh-ehy","type":"blocks","created_at":"2026-02-03T23:41:22.744253+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-ybt","depends_on_id":"dictate.sh-1jx","type":"blocks","created_at":"2026-02-03T23:41:22.848927+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ylf","title":"Restructure CLI for subcommands","description":"Restructure src/dictate/cli.py to support subcommands while preserving backward compatibility.\n\nCHANGE src/dictate/cli.py:\n\n1. Extract _add_shared_stt_args(parser) helper:\n   Moves these args into a reusable function: --model, --language, --context, --context-file (mutually exclusive), --transcribe-interval, --vad-frame-ms, --vad-mode, --vad-silence-ms, --min-words, --device, --list-devices\n\n2. Restructure build_arg_parser():\n   - Top-level parser keeps shared STT args + transcribe-only args (--analyze, --llm-model, --no-ui)\n   - Add subparsers = parser.add_subparsers(dest=\"subcommand\")\n   - Add \"notes\" subparser with:\n     - Shared STT args via _add_shared_stt_args()\n     - --rewrite-model (required) — e.g. \"ollama/llama3.2\", \"openai/gpt-4o-mini\"\n     - --system-prompt and --system-prompt-file (mutually exclusive group)\n     - --notes-file (optional, overrides default notes directory)\n\n3. Restructure main():\n   - Dispatch: if args.subcommand == \"notes\" -\u003e _run_notes(args), else _run_transcribe(args)\n   - _run_transcribe(args): existing behavior, unchanged\n   - _run_notes(args): builds RewriteConfig + NotesConfig, calls run_notes_pipeline()\n\nCRITICAL: bare \"dictate\" (no subcommand) MUST work identically to today. All existing flags remain on top-level parser.\n\nFILES: src/dictate/cli.py\nDEPENDS ON: dictate.sh-bia (context args already added), dictate.sh-1l1 (notes.py exists)\nVERIFY:\n- uv run dictate --help — shows subcommands and existing flags\n- uv run dictate notes --help — shows notes-specific flags\n- uv run dictate --model foo --list-devices — original behavior unchanged","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:41:04.313569+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T23:41:04.313569+05:30","dependencies":[{"issue_id":"dictate.sh-ylf","depends_on_id":"dictate.sh-bia","type":"blocks","created_at":"2026-02-03T23:41:23.225016+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-ylf","depends_on_id":"dictate.sh-1l1","type":"blocks","created_at":"2026-02-03T23:41:23.321645+05:30","created_by":"Ravindra R. Jaju"}]}
