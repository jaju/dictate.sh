{"id":"dictate.sh-09p","title":"Create __init__.py files for package and subpackages","description":"Create:\n- src/dictate/__init__.py: __version__ = '0.1.0' only. No eager re-exports (avoid triggering MLX import).\n- src/dictate/audio/__init__.py: re-export RingBuffer, VoiceActivityDetector, VadConfig\n- src/dictate/model/__init__.py: re-export Qwen3ASRModel, load_qwen3_asr\nKeep audio/ and model/ __init__.py imports lazy-safe (these modules import MLX).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:55.807799+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:51.215107+05:30","closed_at":"2026-02-03T21:57:51.215107+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-6ws","type":"blocks","created_at":"2026-02-03T21:41:11.07059+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-eyb","type":"blocks","created_at":"2026-02-03T21:41:11.136323+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-09p","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:11.201193+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-1gz","title":"Rename CLI flags to match new config structure","description":"## Goal\nRename CLI flags that have drifted from the new config schema. CLI flags override config.json values when supplied.\n\n## Renames\n\n| Current Flag | New Flag | Config Path | Reason |\n|---|---|---|---|\n| `--model` | `--asr-model` | `audio.asr.model` | Ambiguous — three models now |\n| `--llm-model` | `--analysis-model` | `audio.analysis.model` | Matches `audio.analysis` |\n| `--system-prompt` | `--rewrite-prompt` | `litellm_postprocess.prompt` | It's the rewrite LLM prompt, not generic |\n| `--system-prompt-file` | `--rewrite-prompt-file` | `litellm_postprocess.prompt_file` | Same |\n| `--context-bias` | `--asr-logit-bias` | `audio.asr.logit_bias.scale` | Matches config naming |\n\n## Unchanged Flags (still clear)\n`--rewrite-model`, `--context`, `--context-file`, `--vad-frame-ms`, `--vad-mode`, `--vad-silence-ms`, `--min-words`, `--max-buffer`, `--energy-threshold`, `--device`, `--list-devices`, `--analyze`, `--no-ui`, `--notes-file`, `--config-file`, `--transcribe-interval`\n\n## CLI-Config Override Rules\nCLI flags take precedence over config.json values. When a CLI flag is supplied, it overrides the corresponding config.json field. When not supplied, the config.json value is used. When neither exists, the constant default applies.\n\n## No Backward Compatibility\nOld flag names are removed entirely. No aliases, no deprecation.\n\n## Key Files\n- `src/voiss/cli.py` — `_add_shared_stt_args()`, `build_arg_parser()`, `_run_transcribe()`, `_run_notes()`\n- All flag references downstream in `pipeline.py`, `notes.py`","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:45:00.713177+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:45:00.713177+05:30","dependencies":[{"issue_id":"dictate.sh-1gz","depends_on_id":"dictate.sh-5m4","type":"blocks","created_at":"2026-02-05T18:45:53.123085+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-1jx","title":"Add litellm dependency","description":"Add litellm as a project dependency for LLM-based transcript rewriting.\n\nCHANGE pyproject.toml:\n- Add \"litellm\u003e=1.40\" to the dependencies list (after the existing deps like rich, webrtcvad-wheels, etc.)\n\nlitellm provides a unified completion() API supporting Ollama, OpenAI, Claude, and 100+ providers. Used by the notes pipeline to rewrite transcripts via external LLMs.\n\nFILES: pyproject.toml\nVERIFY: uv sync \u0026\u0026 .venv/bin/python -c \"import litellm; print(litellm.__version__)\"","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:14.829359+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T08:46:44.728034+05:30","closed_at":"2026-02-04T08:46:44.728034+05:30","close_reason":"Closed"}
{"id":"dictate.sh-1l1","title":"Create src/dictate/notes.py","description":"Create the notes pipeline orchestrator at src/dictate/notes.py. This module wires up STT + LLM rewriting + file output.\n\nCREATE src/dictate/notes.py with:\n\n1. NotesConfig(frozen=True, slots=True) dataclass:\n   - rewrite: RewriteConfig\n   - output_path: Path\n\n2. resolve_notes_path(notes_file: str | None) -\u003e Path:\n   - Priority: --notes-file flag (absolute or relative to cwd) \u003e DICTATE_NOTES_DIR env var \u003e ~/.local/share/dictate/notes/\n   - Creates directory with mkdir(parents=True, exist_ok=True)\n   - Auto-names file as YYYY-MM-DD_HHMM.md (datetime.now())\n   - Returns resolved Path\n\n3. load_system_prompt(prompt: str | None, file: str | None) -\u003e str | None:\n   - Returns prompt if given, else reads file contents, else None\n\n4. write_session_header(path: Path) -\u003e None:\n   - Writes \"# Notes — YYYY-MM-DD HH:MM\\n\\n\" to new file\n\n5. append_turn(path: Path, result: RewriteResult) -\u003e None:\n   - Opens file in append mode\n   - Writes result.rewritten + \"\\n\\n\" (or result.original on error with LOGGER.warning)\n   - Flushes immediately for crash resilience\n\n6. run_notes_pipeline(model_path, language, context, transcribe_interval, vad_frame_ms, vad_mode, vad_silence_ms, min_words, device, notes_config) -\u003e None:\n   - Creates RealtimeTranscriber with no_ui=True, analyze=False, context=context\n   - Passes async on_turn_complete closure that:\n     a. Increments turn_count\n     b. Logs turn to stderr: LOGGER.info(\"Turn %d: %s\", ...)\n     c. Calls rewrite_transcript via asyncio.to_thread()\n     d. Calls append_turn()\n     e. Logs rewrite success\n   - Logs output file path at startup\n   - Calls await transcriber.run()\n\nFILES: src/dictate/notes.py\nDEPENDS ON: dictate.sh-ybt (rewrite.py), dictate.sh-fr1 (on_turn_complete callback)\nVERIFY: .venv/bin/python -c \"from dictate.notes import NotesConfig, resolve_notes_path, run_notes_pipeline\"","notes":"CONTEXT FROM dictate.sh-ybt: rewrite.py created at src/dictate/rewrite.py. Imports: from dictate.rewrite import RewriteConfig, RewriteResult, rewrite_transcript. RewriteConfig fields: model (str), system_prompt (str, default from constants), max_tokens (int, default 2048). rewrite_transcript(text, config) -\u003e RewriteResult is blocking, use asyncio.to_thread().\n\nCONTEXT FROM dictate.sh-fr1: on_turn_complete callback added to RealtimeTranscriber.__init__ at pipeline.py:69 (on_turn_complete: Callable[[str], Any] | None = None). It is awaited at pipeline.py:203-204, after self.pending_analysis is set but before buffer reset. The full __init__ signature is now: model_path, language, transcribe_interval, vad_frame_ms, vad_mode, vad_silence_ms, min_words, analyze, llm_model, device, no_ui, context, on_turn_complete.","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:52.156197+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T09:04:06.898265+05:30","closed_at":"2026-02-04T09:04:06.898265+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-1l1","depends_on_id":"dictate.sh-ybt","type":"blocks","created_at":"2026-02-03T23:41:23.03803+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-1l1","depends_on_id":"dictate.sh-fr1","type":"blocks","created_at":"2026-02-03T23:41:23.131514+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-1u9","title":"Wire new config into CLI and pipeline (config-CLI merge)","description":"## Goal\nConnect the restructured VoissConfig (from beads issue: restructure config schema) and renamed CLI flags (from beads issue: rename CLI flags) so that config.json values are used as defaults, CLI flags override them, and all values flow correctly to RealtimeTranscriber, run_notes_pipeline, and VoissNotesApp.\n\n## Merge Logic\nFor each configurable field:\n1. Load from config.json via `load_config()`\n2. If CLI flag was explicitly supplied, use CLI value\n3. If CLI flag was not supplied (is at its argparse default), use config value\n4. If neither, use constant default\n\nThis requires detecting whether a CLI flag was explicitly passed vs defaulted. One approach: set argparse defaults to `None` for config-overridable flags, then merge with config values in `_run_transcribe()` and `_run_notes()`.\n\n## Fields to Wire\n- `audio.asr.model` ← `--asr-model` (currently `--model`)\n- `audio.asr.context` ← `--context` / `--context-file` (merge: config first, CLI appended)\n- `audio.asr.logit_bias.scale` ← `--asr-logit-bias` (currently `--context-bias`)\n- `audio.analysis.model` ← `--analysis-model` (currently `--llm-model`)\n- `litellm_postprocess.model` ← `--rewrite-model`\n- `litellm_postprocess.prompt`/`prompt_file` ← `--rewrite-prompt`/`--rewrite-prompt-file`\n\n## Key Files\n- `src/voiss/cli.py` — merge logic in `_run_transcribe()` and `_run_notes()`\n- `src/voiss/rewrite.py` — `VoissConfig` fields consumed here\n- `src/voiss/pipeline.py` — `RealtimeTranscriber` receives merged values\n- `src/voiss/notes.py` — `run_notes_pipeline()` receives merged values","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:45:11.749032+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:45:11.749032+05:30","dependencies":[{"issue_id":"dictate.sh-1u9","depends_on_id":"dictate.sh-5m4","type":"blocks","created_at":"2026-02-05T18:45:55.480954+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-1u9","depends_on_id":"dictate.sh-1gz","type":"blocks","created_at":"2026-02-05T18:45:57.749465+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-2ls","title":"Verify uv sync and CLI entry points work","description":"Run verification steps:\n1. uv sync — ensure package installs in dev mode without errors\n2. uv run dictate --help — verify [project.scripts] entry point works\n3. uv run stt.py --help — verify thin shim resolves imports correctly\n4. uv run dictate --list-devices — verify sounddevice integration works\nFix any import errors, missing modules, or dependency issues discovered.\nThis is the integration test gate — all prior tasks must be complete.","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:38:07.25174+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:04:11.927017+05:30","closed_at":"2026-02-03T22:04:11.927017+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-2ls","depends_on_id":"dictate.sh-7jf","type":"blocks","created_at":"2026-02-03T21:41:11.333855+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-2ls","depends_on_id":"dictate.sh-09p","type":"blocks","created_at":"2026-02-03T21:41:11.400067+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-36o","title":"Update CLAUDE.md and ARCHITECTURE.md for notes feature","description":"Update project documentation to reflect the notes pipeline and context biasing features.\n\nCHANGE CLAUDE.md:\n- Update File Layout to include rewrite.py and notes.py\n- Add litellm\u003e=1.40 to dependencies list\n- Update Run commands to mention \"uv run dictate notes\"\n- Update project description (no longer \"being refactored\" — refactor is complete)\n\nCHANGE ARCHITECTURE.md:\n- Add notes pipeline section describing the two-layer architecture:\n  1. ASR context biasing (domain vocab in Qwen3-ASR system prompt)\n  2. LLM rewriting (litellm -\u003e Ollama/OpenAI for markdown formatting)\n- Document the on_turn_complete callback pattern\n- Document the subcommand CLI structure\n\nFILES: CLAUDE.md, ARCHITECTURE.md\nDEPENDS ON: dictate.sh-ylf (CLI restructure complete — all code done)","status":"closed","priority":3,"issue_type":"chore","owner":"jaju@msync.org","created_at":"2026-02-03T23:41:12.590329+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T09:07:30.7559+05:30","closed_at":"2026-02-04T09:07:30.7559+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-36o","depends_on_id":"dictate.sh-ylf","type":"blocks","created_at":"2026-02-03T23:41:23.4175+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-4rn","title":"Make analysis prompt configurable via config","description":"## Goal\nThe analysis LLM prompt is currently hardcoded as `INTENT_EXPLAIN_PROMPT` in `src/voiss/analysis.py`. Make it configurable via `audio.analysis.prompt` or `audio.analysis.prompt_file` in config.json.\n\n## Current State\n- `analysis.py` has `INTENT_EXPLAIN_PROMPT` (Final constant) with a structured prompt expecting INTENT/ENTITIES/ACTION format\n- `analyze_intent()` uses this constant directly\n- Only activated in transcription mode via `--analyze` flag\n- The analysis LLM model is set via `--analysis-model` (renamed from `--llm-model`)\n\n## Changes\n- `analyze_intent()` should accept an optional `prompt_template: str | None` parameter\n- If provided, use it (must contain `{text}` placeholder). If not, use `INTENT_EXPLAIN_PROMPT` default.\n- `load_config()` reads `audio.analysis.prompt` (inline string) or `audio.analysis.prompt_file` (path, resolved relative to VOISS_CONFIG_DIR). `prompt` takes precedence with warning if both present.\n- Thread through: config → CLI merge → `RealtimeTranscriber` → `analyze_intent()`\n\n## Path Resolution\n`prompt_file` resolves relative to `VOISS_CONFIG_DIR` (default `~/.config/voiss`). Absolute paths used as-is.\n\n## Key Files\n- `src/voiss/analysis.py` — `analyze_intent()` accepts optional prompt\n- `src/voiss/rewrite.py` — `VoissConfig` / `load_config()` reads analysis prompt\n- `src/voiss/pipeline.py` — `RealtimeTranscriber` passes prompt to `analyze_intent()`\n- `src/voiss/cli.py` — thread analysis prompt from config","status":"open","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:45:35.771841+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:45:35.771841+05:30","dependencies":[{"issue_id":"dictate.sh-4rn","depends_on_id":"dictate.sh-5m4","type":"blocks","created_at":"2026-02-05T18:46:01.755659+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-4rn","depends_on_id":"dictate.sh-1u9","type":"blocks","created_at":"2026-02-05T18:46:01.860276+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-590","title":"Create transcribe.py with streaming ASR generator","description":"Create src/dictate/transcribe.py. Extract from stt.py lines 885-970:\n- transcribe() generator function — streams tokens for low-latency output\n- Use collections.abc.Generator not typing.Generator\n- Deferred import of mlx_lm.generate.generate_step inside function body\n- Uses get_feat_extract_output_lengths from model._utils\n- Note: duplicated audio-feature replacement logic exists in both Qwen3ASRModel.__call__ and transcribe(). Keep the transcribe() version (it's the one used at inference time).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:20.924831+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:51.14897+05:30","closed_at":"2026-02-03T21:57:51.14897+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-590","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:10.011174+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-590","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:41:10.080843+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-5iv","title":"Create pipeline.py with slimmed RealtimeTranscriber","description":"Create src/dictate/pipeline.py. Refactor RealtimeTranscriber from stt.py lines 986-1568 into orchestration-only class:\n- __init__: create RingBuffer, VoiceActivityDetector, UiState; store config\n- _audio_callback: thin sounddevice callback (unchanged logic)\n- _processor: async loop coordinating audio capture, VAD, periodic ASR\n- _display: async loop for UI updates and stdout output\n- _handle_turn_complete: orchestrate final transcription + optional analysis\n- run: lifecycle (model loading, warmup, stream, signal handling)\nModule-level function: is_meaningful(text: str) -\u003e bool\nDelegates to: RingBuffer, VoiceActivityDetector, transcribe(), analyze_intent(), ui.render_layout()\nAll self.ui_* attributes replaced by single UiState instance.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:46.455529+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:59:17.436792+05:30","closed_at":"2026-02-03T21:59:17.436792+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-qq8","type":"blocks","created_at":"2026-02-03T21:41:10.34491+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.409543+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-fhb","type":"blocks","created_at":"2026-02-03T21:41:10.476279+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-590","type":"blocks","created_at":"2026-02-03T21:41:10.544215+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-6ws","type":"blocks","created_at":"2026-02-03T21:41:10.610437+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-eyb","type":"blocks","created_at":"2026-02-03T21:41:10.675288+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-cfe","type":"blocks","created_at":"2026-02-03T21:41:10.741883+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-5iv","depends_on_id":"dictate.sh-mit","type":"blocks","created_at":"2026-02-03T21:41:10.807717+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-5m4","title":"Restructure config.json schema and VoissConfig","description":"## Goal\nRestructure config.json from flat keys to a nested schema with two top-level sections: `audio` and `litellm_postprocess`. Update `VoissConfig` dataclass and `load_config()` in `src/voiss/rewrite.py` to parse the new format.\n\n## New Config Schema\n\n```json\n{\n  \"audio\": {\n    \"asr\": {\n      \"model\": \"mlx-community/Qwen3-ASR-0.6B-8bit\",\n      \"context\": [\"Kubernetes\", \"kubectl\", \"etcd\"],\n      \"logit_bias\": { \"terms\": [\"kubectl\"], \"scale\": 5.0 }\n    },\n    \"analysis\": {\n      \"model\": \"mlx-community/Qwen3-0.6B-4bit\",\n      \"prompt\": \"Analyze this speech...\",\n      \"prompt_file\": \"prompts/analysis.md\"\n    },\n    \"corrections\": {\n      \"kube cuddle\": \"kubectl\",\n      \"echo cardiogram\": \"echocardiogram\"\n    }\n  },\n  \"litellm_postprocess\": {\n    \"model\": \"ollama/llama3.2\",\n    \"prompt\": \"Clean up the transcript...\",\n    \"prompt_file\": \"prompts/rewrite.md\",\n    \"domain_vocab\": [\"Kubernetes\", \"kubectl\", \"echocardiogram\"],\n    \"format_instructions\": \"Format as bullet points with sub-points.\",\n    \"flags\": { \"think\": false }\n  }\n}\n```\n\n## Section Purposes\n\n- **`audio`** — Everything running locally via MLX (in-memory models + deterministic text processing)\n  - **`audio.asr`** — Speech recognition model config. `context` = terms for Qwen3-ASR SFT prompt biasing. `logit_bias` = mechanical token probability boost during decoding.\n  - **`audio.analysis`** — Local intent extraction LLM (transcription mode `--analyze`). Currently hardcoded prompt in `analysis.py:INTENT_EXPLAIN_PROMPT`. Make configurable via `prompt`/`prompt_file`.\n  - **`audio.corrections`** — Deterministic regex find-replace applied post-ASR, pre-display, pre-rewrite. Dict of {wrong: correct}. Currently named `replacements` in old config.\n- **`litellm_postprocess`** — External LLM call via litellm for rewrite/formatting\n  - `model` — litellm model string (e.g. `ollama/llama3.2`, `openai/gpt-4o-mini`)\n  - `prompt`/`prompt_file` — Base system prompt for rewrite. Only one should be present; `prompt` takes precedence with a warning if both exist.\n  - `domain_vocab` — Terms injected into the rewrite prompt so the LLM knows the domain\n  - `format_instructions` — Appended to base prompt for structural guidance\n  - `flags` — Dict passed as extra kwargs to litellm `completion()` call (replaces hardcoded `think=False` in `rewrite.py:rewrite_transcript()`)\n\n## Path Resolution\n\n- `VOISS_CONFIG_DIR` env var (default `~/.config/voiss`) is the base directory for config.json and all relative paths.\n- All `prompt_file` / file paths in config.json resolve relative to `VOISS_CONFIG_DIR`. Absolute paths used as-is.\n- `VOISS_CONFIG_DIR=/alt/config uv run voiss notes ...` switches the entire config set.\n\n## Key Files\n- `src/voiss/rewrite.py` — `VoissConfig` dataclass + `load_config()` — main changes here\n- `src/voiss/constants.py` — May need new constants for env var name, defaults\n\n## No Backward Compatibility\nOld flat config format (`context`, `replacements`, `bias` at top level) is dropped entirely. No migration, no deprecation warnings.","status":"open","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:44:48.526706+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:44:48.526706+05:30"}
{"id":"dictate.sh-6ws","title":"Create audio/ring_buffer.py","description":"Create src/dictate/audio/ring_buffer.py. Extract ring buffer logic from RealtimeTranscriber (stt.py lines 1029-1034, 1175-1215):\n- RingBuffer class with __slots__\n- Factory: classmethod create(max_seconds, sample_rate) -\u003e Self\n- Methods: append(frame), get_recent(seconds) -\u003e np.ndarray, reset()\n- Properties: filled_seconds, total_samples_written, sample_rate\n- Track total_samples_written and last_transcribed_sample internally\n- Only depends on numpy","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:05.918827+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.831691+05:30","closed_at":"2026-02-03T21:51:52.831691+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-6ws","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.165941+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-7jf","title":"Replace root stt.py with thin shim","description":"Replace the root stt.py with a thin shim that imports from the package:\n- Keep PEP 723 script metadata block with requires-python\u003e=3.12\n- dependencies list: just 'dictate-stt'\n- [tool.uv.sources] dictate-stt = { path = '.' }\n- Body: from dictate.cli import main; raise SystemExit(main())\n- Keep the original docstring as a one-liner\nThe original full stt.py in docs/ stays unchanged for now (it serves the landing page download).","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:38:01.924491+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:02:04.940174+05:30","closed_at":"2026-02-03T22:02:04.940174+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-7jf","depends_on_id":"dictate.sh-rie","type":"blocks","created_at":"2026-02-03T21:41:11.267533+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-a05","title":"Create config.py with frozen dataclasses and factory","description":"Create src/dictate/config.py. Extract from stt.py lines 180-237:\n- AudioEncoderConfig: @dataclass(frozen=True, slots=True) — all fields from original\n- TextConfig: @dataclass(frozen=True, slots=True) — all fields from original\n- ModelConfig: @dataclass(frozen=True, slots=True) — audio_config, text_config, audio_token_id, support_languages as tuple[str, ...] not list\n- Remove __post_init__ mutation. Add make_model_config(raw: dict[str, Any]) -\u003e ModelConfig factory function that resolves nested dicts into frozen sub-configs before constructing the frozen ModelConfig.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:34:35.071111+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.76498+05:30","closed_at":"2026-02-03T21:51:52.76498+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-a05","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.099916+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-bia","title":"Add ASR context biasing to transcribe.py","description":"Add optional context: str | None parameter to transcribe() in src/dictate/transcribe.py. When provided, inject into Qwen3-ASR system prompt for domain vocabulary biasing.\n\nWHAT: Qwen3-ASR has native context biasing trained during SFT. The system prompt in the chat template (currently empty at transcribe.py:54-55) accepts domain vocabulary text that biases the decoder toward specific terms.\n\nCHANGE transcribe.py:\n- Add context: str | None = None parameter to transcribe() function signature (line 17-24)\n- Change prompt construction (line 54-55) from:\n    f\"\u003c|im_start|\u003esystem\\n\u003c|im_end|\u003e\\n\"\n  to:\n    f\"\u003c|im_start|\u003esystem\\n{context or chr(39)+chr(39)}\u003c|im_end|\u003e\\n\"\n\nCHANGE pipeline.py:\n- Add context: str | None = None parameter to RealtimeTranscriber.__init__ (line 54-67)\n- Store as self.context\n- Pass self.context to transcribe() call in _run_transcribe method (around line 160)\n\nCHANGE cli.py:\n- Add mutually exclusive group with --context (inline string) and --context-file (path to file)\n- In main(), read context-file if provided, pass context string to RealtimeTranscriber\n\nFILES: src/dictate/transcribe.py, src/dictate/pipeline.py, src/dictate/cli.py\nVERIFY: .venv/bin/python -c \"from dictate.transcribe import transcribe; import inspect; assert \\\"context\\\" in inspect.signature(transcribe).parameters\"","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:03.264342+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T08:47:43.478421+05:30","closed_at":"2026-02-04T08:47:43.478421+05:30","close_reason":"Closed"}
{"id":"dictate.sh-c2k","title":"Create model/_utils.py with tensor math helpers","description":"Create src/dictate/model/_utils.py. Extract from stt.py lines 245-267:\n- create_additive_causal_mask(n, offset) -\u003e mx.array\n- floor_div(a, b) -\u003e mx.array  (renamed from _floor_div)\n- get_feat_extract_output_lengths(input_lengths) -\u003e mx.array (renamed from _get_feat_extract_output_lengths)\nUse type statement for aliases: type MaskArray = mx.array\nAll pure functions, no state. Depends on mlx.core.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:25.660127+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.965497+05:30","closed_at":"2026-02-03T21:51:52.965497+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-c2k","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:30.391361+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-cfe","title":"Create analysis.py with IntentResult and analyze_intent","description":"Create src/dictate/analysis.py. Extract from stt.py lines 978-983, 1268-1298:\n- INTENT_EXPLAIN_PROMPT: Final (the prompt template)\n- IntentResult: @dataclass(frozen=True, slots=True) with intent, entities, action fields — replaces dict[str, str]\n- analyze_intent(text, llm, llm_tokenizer) -\u003e IntentResult — pure function\n- Deferred import of mlx_lm.generate.generate inside function body\n- Uses suppress_output from dictate.env\n- Strips \u003cthink\u003e...\u003c/think\u003e tags from LLM output","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:31.349746+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.247231+05:30","closed_at":"2026-02-03T21:54:01.247231+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-cfe","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.148596+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-cfe","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:41:10.214354+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-cys","title":"Create model/decoder.py with text decoder nn.Modules","description":"Create src/dictate/model/decoder.py. Extract from stt.py lines 550-675:\n- TextAttention(nn.Module) — GQA with RoPE, QK-norm\n- TextMLP(nn.Module) — SwiGLU\n- TextDecoderLayer(nn.Module) — pre-norm transformer block\n- TextModel(nn.Module) — embedding + N layers + final RMSNorm\nUse @override on __call__ methods. Import config types from dictate.config, create_additive_causal_mask from dictate.model._utils.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:45.62525+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.179713+05:30","closed_at":"2026-02-03T21:54:01.179713+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-cys","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.591243+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-cys","depends_on_id":"dictate.sh-c2k","type":"blocks","created_at":"2026-02-03T21:39:30.657124+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ehy","title":"Add notes-related constants","description":"Add Final-annotated constants to src/dictate/constants.py for the notes pipeline.\n\nADD to constants.py:\n- DEFAULT_NOTES_DIR: Final = \"~/.local/share/dictate/notes\"\n- DEFAULT_NOTES_DIR_ENV: Final = \"DICTATE_NOTES_DIR\"\n- DEFAULT_REWRITE_MAX_TOKENS: Final = 2048\n- DEFAULT_REWRITE_SYSTEM_PROMPT: Final = \"You are a note-taking assistant. Rewrite the following spoken transcript into clean, structured markdown notes. Preserve all information but improve clarity, fix grammar, and organize with headings or bullet points as appropriate. Output only the markdown, no preamble.\"\n\nFILES: src/dictate/constants.py\nVERIFY: .venv/bin/python -c \"from dictate.constants import DEFAULT_NOTES_DIR, DEFAULT_NOTES_DIR_ENV, DEFAULT_REWRITE_MAX_TOKENS, DEFAULT_REWRITE_SYSTEM_PROMPT; print(DEFAULT_NOTES_DIR)\"","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:09.7547+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T08:46:44.664208+05:30","closed_at":"2026-02-04T08:46:44.664208+05:30","close_reason":"Closed"}
{"id":"dictate.sh-eyb","title":"Create audio/vad.py with VadConfig and VoiceActivityDetector","description":"Create src/dictate/audio/vad.py. Extract VAD logic from RealtimeTranscriber (stt.py lines 1041-1053, 1219-1248):\n- VadConfig: @dataclass(frozen=True, slots=True) with frame_ms, mode, silence_ms, sample_rate\n- VoiceActivityDetector class with __slots__\n- __init__(config: VadConfig) — validates frame_ms in (10,20,30) and mode in 0-3\n- process(frame: np.ndarray) -\u003e bool — returns True on turn complete\n- reset() — clear state for new turn\n- Properties: state ('speech'|'silence'), speech_detected\n- Depends on numpy, webrtcvad-wheels, math","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:17.656072+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.897683+05:30","closed_at":"2026-02-03T21:51:52.897683+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-eyb","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.233994+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-eyz","title":"Implement rewrite prompt composition (domain_vocab + format_instructions)","description":"## Goal\nBuild the final rewrite system prompt by composing the base prompt with optional `domain_vocab` and `format_instructions` from `litellm_postprocess` config section. Also pass `flags` dict to the litellm `completion()` call.\n\n## Prompt Composition\nThe final system prompt sent to litellm is assembled as:\n\n1. **Base prompt** — from `litellm_postprocess.prompt`, `litellm_postprocess.prompt_file`, `--rewrite-prompt` CLI flag, or built-in default (`DEFAULT_REWRITE_SYSTEM_PROMPT` in constants.py)\n2. **+ Domain vocabulary section** — if `litellm_postprocess.domain_vocab` is non-empty, append: `\\nThe following domain terms should be used correctly: X, Y, Z`\n3. **+ Format instructions** — if `litellm_postprocess.format_instructions` is non-empty, append the text as-is\n\nWrite a pure function `compose_rewrite_prompt(base: str, domain_vocab: list[str], format_instructions: str | None) -\u003e str` in `rewrite.py`.\n\n## litellm Flags\nCurrently `rewrite_transcript()` in `rewrite.py` hardcodes `think=False` in the `completion()` call (line ~164). Replace with:\n- Read `flags` dict from config (`litellm_postprocess.flags`)\n- Spread as `**flags` into the `completion()` call\n- Default to `{\"think\": False}` if `flags` is not present in config, to preserve current behavior\n\n## Key Files\n- `src/voiss/rewrite.py` — `compose_rewrite_prompt()` function, update `RewriteConfig` to carry domain_vocab/format_instructions/flags, update `rewrite_transcript()`\n- `src/voiss/cli.py` — pass new RewriteConfig fields from merged config","status":"open","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:45:24.247235+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:45:24.247235+05:30","dependencies":[{"issue_id":"dictate.sh-eyz","depends_on_id":"dictate.sh-5m4","type":"blocks","created_at":"2026-02-05T18:45:59.468878+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-fhb","title":"Create model/__init__.py with re-exports","description":"Create src/dictate/model/__init__.py. Re-export:\n- Qwen3ASRModel from dictate.model.asr\n- load_qwen3_asr from dictate.model.loader\nThese are the public API of the model subpackage.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:12.474512+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:57:07.759132+05:30","closed_at":"2026-02-03T21:57:07.759132+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-fhb","depends_on_id":"dictate.sh-sc4","type":"blocks","created_at":"2026-02-03T21:39:31.124+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-fhb","depends_on_id":"dictate.sh-hm5","type":"blocks","created_at":"2026-02-03T21:39:31.190768+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-fr1","title":"Add on_turn_complete callback to RealtimeTranscriber","description":"Add an optional async callback to RealtimeTranscriber that fires when a turn is finalized. This is the integration point for the notes pipeline.\n\nCHANGE src/dictate/pipeline.py:\n\n1. Add import at top: from collections.abc import Callable\n\n2. Add parameter to __init__ (line 54-67):\n   on_turn_complete: Callable[[str], Any] | None = None\n   Store as self.on_turn_complete\n\n3. In _handle_turn_complete() (around line 200-204), AFTER:\n   self.pending_analysis = (final_transcript, analysis_result)\n   and BEFORE the buffer reset (line 205), add:\n   if self.on_turn_complete is not None:\n       await self.on_turn_complete(final_transcript)\n\nDESIGN NOTES:\n- The callback is awaited sequentially — turns are processed in order (no out-of-order file writes)\n- The callback does NOT hold the GPU lock — litellm calls go to external LLM, not local MLX GPU\n- Backward-compatible: existing callers pass nothing, behavior unchanged\n- The callback runs AFTER analysis (if enabled) but BEFORE buffer reset\n\nFILES: src/dictate/pipeline.py\nDEPENDS ON: dictate.sh-bia (context biasing, since both touch pipeline.py — avoids merge conflicts)\nVERIFY: .venv/bin/python -c \"from dictate.pipeline import RealtimeTranscriber; import inspect; sig = inspect.signature(RealtimeTranscriber.__init__); assert \\\"on_turn_complete\\\" in sig.parameters\"","notes":"CONTEXT FROM dictate.sh-bia: context param added to RealtimeTranscriber.__init__ at pipeline.py:67 (context: str | None = None), stored as self.context at line 70. The __init__ signature is now: model_path, language, transcribe_interval, vad_frame_ms, vad_mode, vad_silence_ms, min_words, analyze, llm_model, device, no_ui, context. Add on_turn_complete after context in the parameter list.","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:36.872758+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T09:03:23.758644+05:30","closed_at":"2026-02-04T09:03:23.758644+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-fr1","depends_on_id":"dictate.sh-bia","type":"blocks","created_at":"2026-02-03T23:41:22.945576+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-hm5","title":"Create model/loader.py with load_qwen3_asr function","description":"Create src/dictate/model/loader.py. Extract from stt.py lines 789-877:\n- load_qwen3_asr(model_path: str) -\u003e tuple[Qwen3ASRModel, TokenizerLike, FeatureExtractorLike]\n- Replace glob.glob with Path.glob\n- Use make_model_config() factory from dictate.config\n- Keep trust_remote_code=True (required by Qwen3 tokenizer)\n- Keep strict=False weight loading (model weight format varies)\nDepends on mlx, json, pathlib, huggingface_hub, transformers, config, asr, protocols.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:07.44807+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:48.581952+05:30","closed_at":"2026-02-03T21:56:48.581952+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.923634+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-sc4","type":"blocks","created_at":"2026-02-03T21:39:30.99023+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-hm5","depends_on_id":"dictate.sh-oej","type":"blocks","created_at":"2026-02-03T21:39:31.058119+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-htw","title":"Create env.py with environment setup and logging","description":"Create src/dictate/env.py. Extract from stt.py:\n- Lines 71-84: warning filters + os.environ setup → setup_environment() function\n- Lines 128-142: _suppress_output() context manager → suppress_output() (public name)\n- Line 125: LOGGER = logging.getLogger('speech')\nOnly stdlib imports (contextlib, io, os, logging, warnings). setup_environment() must be called before any MLX imports.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:33:59.074448+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.629838+05:30","closed_at":"2026-02-03T21:51:52.629838+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-htw","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:15.969408+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ma1","title":"Create pyproject.toml with uv project config","description":"Create pyproject.toml at project root with:\n- name='dictate-stt', version='0.1.0', requires-python='\u003e=3.12'\n- Updated dependencies: mlx\u003e=0.30.0, mlx-lm\u003e=0.30.0, numpy\u003e=2.0, sounddevice\u003e=0.5, transformers\u003e=4.47, huggingface-hub\u003e=0.27, webrtcvad-wheels\u003e=2.0.14, rich\u003e=14.0\n- Drop setuptools (unused transitive dep)\n- [project.scripts] dictate = 'dictate.cli:main'\n- [build-system] hatchling\n- [tool.hatch.build.targets.wheel] packages = ['src/dictate']\n- Create src/dictate/ directory structure with empty __init__.py files for: dictate/, dictate/model/, dictate/audio/","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:32:38.93503+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:47:19.849875+05:30","closed_at":"2026-02-03T21:47:19.849875+05:30","close_reason":"Closed"}
{"id":"dictate.sh-mit","title":"Create ui.py with UiState and pure render functions","description":"Create src/dictate/ui.py. Extract rendering from RealtimeTranscriber (stt.py lines 1086-1168):\n- UiState: @dataclass(slots=True) — snapshot of all pipeline state needed for rendering\n  Fields: status, partial_transcript, history (list of (str, IntentResult|None)), max_history, vad_state, buffer_seconds, queue_size, asr_ms, analysis_ms, language, vad_mode, vad_frame_ms, model_path, llm_model_name, analyze_enabled, turn_complete\n- short_model_name(name: str | None) -\u003e str — extract last path segment\n- render_status_panel(state: UiState) -\u003e Panel\n- render_transcript_panel(state: UiState) -\u003e Panel\n- render_stats_panel(state: UiState) -\u003e Panel\n- render_layout(state: UiState) -\u003e Layout\nAll render functions are pure: take UiState in, return Rich renderables out. No side effects.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:39.059004+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:13.006272+05:30","closed_at":"2026-02-03T21:56:13.006272+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-mit","depends_on_id":"dictate.sh-cfe","type":"blocks","created_at":"2026-02-03T21:41:10.27998+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-n6l","title":"Update README and example config for new schema","description":"## Goal\nUpdate all documentation to reflect the new config schema, renamed CLI flags, and new features.\n\n## Changes\n\n### README.md\n- **Shared Options table**: Rename flags (`--model` → `--asr-model`, `--llm-model` → `--analysis-model`, `--system-prompt` → `--rewrite-prompt`, `--system-prompt-file` → `--rewrite-prompt-file`, `--context-bias` → `--asr-logit-bias`)\n- **Config section**: Replace the flat config example with the new nested schema. Explain the two top-level sections: `audio` (local MLX pipeline) and `litellm_postprocess` (external LLM). Document each field.\n- **Quick Start examples**: Update CLI invocations to use new flag names\n- **Domain Vocabulary section**: Update to explain how `audio.asr.context` (ASR biasing) differs from `litellm_postprocess.domain_vocab` (rewrite LLM awareness)\n- **Troubleshooting**: Update flag names in tips\n- **Document VOISS_CONFIG_DIR**: Explain env var for switching config sets, path resolution for prompt_file fields\n\n### examples/config.json\n- Rewrite to use the new nested schema\n- Include comments (or a companion README) explaining each section\n\n### CLAUDE.md / ARCHITECTURE.md\n- Update if they reference old config structure or old CLI flag names\n\n## Key Files\n- `README.md`\n- `examples/config.json` (if it exists, or create)\n- `CLAUDE.md`, `ARCHITECTURE.md`","status":"open","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-05T18:45:47.22878+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-05T18:45:47.22878+05:30","dependencies":[{"issue_id":"dictate.sh-n6l","depends_on_id":"dictate.sh-5m4","type":"blocks","created_at":"2026-02-05T18:46:04.558088+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-n6l","depends_on_id":"dictate.sh-1gz","type":"blocks","created_at":"2026-02-05T18:46:04.661621+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-n6l","depends_on_id":"dictate.sh-1u9","type":"blocks","created_at":"2026-02-05T18:46:04.759556+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-n6l","depends_on_id":"dictate.sh-eyz","type":"blocks","created_at":"2026-02-05T18:46:04.853042+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-n6l","depends_on_id":"dictate.sh-4rn","type":"blocks","created_at":"2026-02-05T18:46:04.944934+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-oej","title":"Create protocols.py with TokenizerLike and FeatureExtractorLike","description":"Create src/dictate/protocols.py. Extract Protocol classes from stt.py lines 150-172. Modernize:\n- Use list[int], dict[str, Any] not List/Dict\n- Use collections.abc.Sequence not typing.Sequence\n- Keep as Protocol classes (structural typing, no implementation)","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:34:14.499002+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.696398+05:30","closed_at":"2026-02-03T21:51:52.696398+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-oej","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:16.034135+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-qq8","title":"Create constants.py with Final-annotated defaults","description":"Create src/dictate/constants.py. Extract all DEFAULT_* constants from stt.py lines 109-119. Use typing.Final annotations. Use underscore separators in numbers (16_000). No imports beyond typing.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:33:49.788192+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:51:52.561949+05:30","closed_at":"2026-02-03T21:51:52.561949+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-qq8","depends_on_id":"dictate.sh-ma1","type":"blocks","created_at":"2026-02-03T21:39:15.901435+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-rie","title":"Create cli.py with argparse and main entry point","description":"Create src/dictate/cli.py. Extract from stt.py lines 1576-1688:\n- build_arg_parser() -\u003e argparse.ArgumentParser\n- list_audio_devices() -\u003e None (Rich table of input devices)\n- main() -\u003e int\nmain() must call setup_environment() BEFORE importing pipeline (which transitively imports MLX).\nUse deferred import: import pipeline inside main() body after setup_environment().\nConfigure logging with RichHandler to stderr.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:37:51.041499+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T22:01:44.297962+05:30","closed_at":"2026-02-03T22:01:44.297962+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-qq8","type":"blocks","created_at":"2026-02-03T21:41:10.873246+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-htw","type":"blocks","created_at":"2026-02-03T21:41:10.939345+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-rie","depends_on_id":"dictate.sh-5iv","type":"blocks","created_at":"2026-02-03T21:41:11.004923+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-sc4","title":"Create model/asr.py with Qwen3ASRModel composite","description":"Create src/dictate/model/asr.py. Extract from stt.py lines 678-781:\n- Qwen3ASRModel(nn.Module) — composes AudioEncoder + TextModel\n- get_audio_features(), __call__() with @override, make_cache(), sanitize() @staticmethod\n- type Weights = dict[str, mx.array]\n- Properties: layers, sample_rate\nImport AudioEncoder from encoder.py, TextModel from decoder.py, ModelConfig from config.py.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:36:42.445267+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:56:12.939297+05:30","closed_at":"2026-02-03T21:56:12.939297+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.723225+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-wzi","type":"blocks","created_at":"2026-02-03T21:39:30.789213+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-sc4","depends_on_id":"dictate.sh-cys","type":"blocks","created_at":"2026-02-03T21:39:30.855584+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-wzi","title":"Create model/encoder.py with audio encoder nn.Modules","description":"Create src/dictate/model/encoder.py. Extract from stt.py lines 270-547:\n- SinusoidalPositionEmbedding(nn.Module)\n- AudioAttention(nn.Module)\n- AudioEncoderLayer(nn.Module)\n- AudioEncoder(nn.Module)\nExtract stateless helpers as module-level functions (not methods):\n- compute_chunk_layout(feature_lens, chunk_size) -\u003e tuple[np.ndarray, np.ndarray]\n- slice_feature_chunks(...) -\u003e list[mx.array]\n- pad_chunks(...) -\u003e tuple[mx.array, int]\n- build_cu_seqlens(...) -\u003e list[int]\nUse @override on __call__ methods. Import config types from dictate.config, utils from dictate.model._utils.","status":"closed","priority":2,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T21:35:33.67463+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-03T21:54:01.111955+05:30","closed_at":"2026-02-03T21:54:01.111955+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-wzi","depends_on_id":"dictate.sh-a05","type":"blocks","created_at":"2026-02-03T21:39:30.458803+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-wzi","depends_on_id":"dictate.sh-c2k","type":"blocks","created_at":"2026-02-03T21:39:30.524758+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ybt","title":"Create src/dictate/rewrite.py","description":"Create the LLM rewriting module at src/dictate/rewrite.py. Analogous to analysis.py but for transcript-to-markdown rewriting via litellm.\n\nCREATE src/dictate/rewrite.py with:\n\n1. RewriteConfig(frozen=True, slots=True) dataclass:\n   - model: str (e.g. \"ollama/llama3.2\", \"openai/gpt-4o-mini\")\n   - system_prompt: str = DEFAULT_REWRITE_SYSTEM_PROMPT (from constants)\n   - max_tokens: int = DEFAULT_REWRITE_MAX_TOKENS (from constants)\n\n2. RewriteResult(frozen=True, slots=True) dataclass:\n   - original: str (raw transcript)\n   - rewritten: str (LLM output)\n   - model: str (which model was used)\n   - error: str = \"\" (non-empty on failure)\n\n3. rewrite_transcript(text: str, config: RewriteConfig) -\u003e RewriteResult:\n   - Blocking function (designed for asyncio.to_thread)\n   - Deferred import: from litellm import completion\n   - Sends system_prompt as system role, text as user role\n   - Captures ALL exceptions in result.error (does not raise) — pipeline must keep going\n   - Returns RewriteResult\n\nPATTERNS TO FOLLOW (from analysis.py):\n- Frozen dataclass results\n- Deferred imports inside function body\n- Pure function, no state, no side effects beyond LLM call\n- Use Python 3.12 types: str | None, not Optional[str]\n\nFILES: src/dictate/rewrite.py\nDEPENDS ON: dictate.sh-ehy (constants), dictate.sh-1jx (litellm dep)\nVERIFY: .venv/bin/python -c \"from dictate.rewrite import RewriteConfig, RewriteResult, rewrite_transcript\"","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:40:26.405534+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T09:03:23.688737+05:30","closed_at":"2026-02-04T09:03:23.688737+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-ybt","depends_on_id":"dictate.sh-ehy","type":"blocks","created_at":"2026-02-03T23:41:22.744253+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-ybt","depends_on_id":"dictate.sh-1jx","type":"blocks","created_at":"2026-02-03T23:41:22.848927+05:30","created_by":"Ravindra R. Jaju"}]}
{"id":"dictate.sh-ylf","title":"Restructure CLI for subcommands","description":"Restructure src/dictate/cli.py to support subcommands while preserving backward compatibility.\n\nCHANGE src/dictate/cli.py:\n\n1. Extract _add_shared_stt_args(parser) helper:\n   Moves these args into a reusable function: --model, --language, --context, --context-file (mutually exclusive), --transcribe-interval, --vad-frame-ms, --vad-mode, --vad-silence-ms, --min-words, --device, --list-devices\n\n2. Restructure build_arg_parser():\n   - Top-level parser keeps shared STT args + transcribe-only args (--analyze, --llm-model, --no-ui)\n   - Add subparsers = parser.add_subparsers(dest=\"subcommand\")\n   - Add \"notes\" subparser with:\n     - Shared STT args via _add_shared_stt_args()\n     - --rewrite-model (required) — e.g. \"ollama/llama3.2\", \"openai/gpt-4o-mini\"\n     - --system-prompt and --system-prompt-file (mutually exclusive group)\n     - --notes-file (optional, overrides default notes directory)\n\n3. Restructure main():\n   - Dispatch: if args.subcommand == \"notes\" -\u003e _run_notes(args), else _run_transcribe(args)\n   - _run_transcribe(args): existing behavior, unchanged\n   - _run_notes(args): builds RewriteConfig + NotesConfig, calls run_notes_pipeline()\n\nCRITICAL: bare \"dictate\" (no subcommand) MUST work identically to today. All existing flags remain on top-level parser.\n\nFILES: src/dictate/cli.py\nDEPENDS ON: dictate.sh-bia (context args already added), dictate.sh-1l1 (notes.py exists)\nVERIFY:\n- uv run dictate --help — shows subcommands and existing flags\n- uv run dictate notes --help — shows notes-specific flags\n- uv run dictate --model foo --list-devices — original behavior unchanged","notes":"CONTEXT FROM dictate.sh-bia: --context and --context-file already added to cli.py as mutually exclusive group (lines 65-75). Context is read in main() at lines 142-145 (from pathlib import Path; context = args.context; if args.context_file: context = Path(args.context_file).read_text().strip()). These args need to be moved into _add_shared_stt_args() during CLI restructure so they appear on both the top-level parser and the notes subparser.\nCONTEXT FROM dictate.sh-1l1: notes.py created at src/dictate/notes.py. Key imports for cli.py: from dictate.notes import NotesConfig, resolve_notes_path, load_system_prompt, run_notes_pipeline. from dictate.rewrite import RewriteConfig. run_notes_pipeline signature: (model_path, language, context, transcribe_interval, vad_frame_ms, vad_mode, vad_silence_ms, min_words, device, notes_config). Notes mode uses no_ui=True and analyze=False internally.","status":"closed","priority":1,"issue_type":"task","owner":"jaju@msync.org","created_at":"2026-02-03T23:41:04.313569+05:30","created_by":"Ravindra R. Jaju","updated_at":"2026-02-04T09:06:09.302473+05:30","closed_at":"2026-02-04T09:06:09.302473+05:30","close_reason":"Closed","dependencies":[{"issue_id":"dictate.sh-ylf","depends_on_id":"dictate.sh-bia","type":"blocks","created_at":"2026-02-03T23:41:23.225016+05:30","created_by":"Ravindra R. Jaju"},{"issue_id":"dictate.sh-ylf","depends_on_id":"dictate.sh-1l1","type":"blocks","created_at":"2026-02-03T23:41:23.321645+05:30","created_by":"Ravindra R. Jaju"}]}
